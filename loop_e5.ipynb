{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93aa159a-781a-4f26-bc28-30906700f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import TSNE\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "\n",
    "import pymorphy2\n",
    "import re\n",
    "import spacy\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "data_path = \"data/\"\n",
    "COLUMN = \"description\"\n",
    "\n",
    "import os\n",
    "print(os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "id": "e1a6c9ec-ed56-4b73-8222-f38cfdccbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "\n",
    "def clickRequest(query: str):\n",
    "    client = Client(\n",
    "        host = \"144.126.249.217\",\n",
    "        port = 9000,\n",
    "        user = 'smartsales',\n",
    "        password = 'lMZybloPciKL0pxS1iEjc7rK8kK79hPH',\n",
    "        database = 'smartsales',\n",
    "        connect_timeout=180,\n",
    "        sync_request_timeout=90\n",
    "    )\n",
    "\n",
    "    data = client.execute(query)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "id": "17451b4a-a5d5-47b8-ba63-c5c8661287a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"select\n",
    "        id,\n",
    "        min(created_ts) as date_arrival,\n",
    "        anyLast(category_id) as category_id\n",
    "    from wb_products\n",
    "    group by id\n",
    "    HAVING date_arrival >= '2023-08-10' AND date_arrival <= '2023-09-10'\n",
    "    SETTINGS max_bytes_before_external_group_by = 100000000\n",
    "\"\"\"\n",
    "\n",
    "clms = [\"id\", \"date_arrival\", \"category_id\"]\n",
    "\n",
    "df = pd.DataFrame(clickRequest(query), columns=clms)\n",
    "\n",
    "df.to_parquet(\"data/products_arrival_08100910.parquet.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "1b998068-0416-439a-bae4-2fd231f97163",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"select\n",
    "        id,\n",
    "        max(created_ts) as date_update,\n",
    "        anyLast(title) as title,\n",
    "        anyLast(description) as description,\n",
    "        argMax(price, created_ts) as price,\n",
    "        argMax(discount_price, created_ts) as discount_price,\n",
    "        anyLast(supplier_id) as supplier_id,\n",
    "        argMax(review_rating, created_ts) as review_rating,\n",
    "        argMax(review_number, created_ts) as review_number,\n",
    "        argMax(stock_qty, created_ts) as stock_qty,\n",
    "        anyLast(sale_qty) as sale_qty,\n",
    "        anyLast(revenue) as revenue,\n",
    "        anyLast(category_id) as category_id\n",
    "    from wb_products\n",
    "    where toDate(created_ts) >= '2023-09-02' AND toDate(created_ts) <= '2023-09-08'\n",
    "    group by id, toDate(created_ts)\n",
    "    SETTINGS max_bytes_before_external_group_by = 100000000\n",
    "\"\"\"\n",
    "\n",
    "clms = [\"id\", \"date_update\", \"title\", \"description\", \"price\", \"discount_price\", \"supplier_id\", \n",
    "    \"review_rating\", \"review_number\", \"stock_qty\", \"sale_qty\", \"revenue\", \"category_id\"]\n",
    "\n",
    "df = pd.DataFrame(clickRequest(query), columns=clms)\n",
    "\n",
    "df.to_parquet(\"data/downloads/products09020908.parquet.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "7f18ac3c-1b10-49ec-a21d-6689bbda7ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22465ac2-f685-4c95-b80e-f51f67b91a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1831218, 12) 24857\n",
      "(1806361, 12) 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet(data_path+\"wb_products.parquet.gzip\")\n",
    "print(df.shape, df.description.isna().sum())\n",
    "df = df.dropna(subset=['description']).reset_index(drop=True)\n",
    "print(df.shape, df.description.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe3020c-e3a6-4b36-8d77-54af5098d50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5fb4e77-aa96-43f1-8a55-8e1b3612f64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1811222, 13)\n"
     ]
    }
   ],
   "source": [
    "# join data done\n",
    "df_done = pd.concat([\n",
    "    pd.read_parquet(data_path+\"keywords/df_keywords.parquet.gzip\"),\n",
    "    pd.read_parquet(data_path+\"keywords/_df_keywords.parquet.gzip\")\n",
    "]).reset_index(drop=True)\n",
    "print(df_done.shape)\n",
    "\n",
    "df_done.to_parquet(data_path+\"keywords/df_keywords.parquet.gzip\", index=False, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b523bcd2-0d30-4665-ab7d-9f94f6c29cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 12)\n"
     ]
    }
   ],
   "source": [
    "# already processed\n",
    "df_done = pd.read_parquet(data_path+\"keywords/df_keywords.parquet.gzip\")\n",
    "df = df[~df.id.isin(df_done.id.values)].reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7ed7dc7-fdbe-4257-b564-93ccc520848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf6f3170-0dae-400e-a484-4cf2fb17a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean \n",
    "df[COLUMN] = df[COLUMN].apply(lambda v: v.replace(\"\\\\n\", \"\").replace(\"\\n\", \"\").replace(\"\\\\\", \"\").replace('\"', '').replace(\"-\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55587c84-abe8-46ba-baaa-808b81590438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_number(input_string):\n",
    "    return bool(re.search(r'\\d', input_string))\n",
    "\n",
    "def contains_latin_punct_characters(input_string):\n",
    "    return any(ord(char) < 128 for char in input_string)\n",
    "\n",
    "def extract_keywords(text, nlp):\n",
    "\n",
    "    doc = nlp(text)\n",
    "    keywords = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.text in nlp.Defaults.stop_words:\n",
    "            continue\n",
    "        elif token.text in punctuation:\n",
    "            continue\n",
    "        elif len(token.text) < 3:\n",
    "            continue\n",
    "        elif contains_number(token.text) == True:\n",
    "            continue\n",
    "        elif contains_latin_punct_characters(token.text) == True:\n",
    "            continue\n",
    "        elif token.pos_ in [\"PROPN\", 'X']:\n",
    "            continue\n",
    "        elif token.pos_ in [\"NOUN\", \"ADJ\"] or token.ent_type_:\n",
    "            keywords.append(token.text.lower())\n",
    "\n",
    "    return keywords\n",
    "\n",
    "nlp = spacy.load('ru_core_news_md')\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "df_keywords = pd.DataFrame(dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b56b0795-c749-4c73-b4b3-a60ee42da0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 100%|██████████| 7/7 [05:06<00:00, 43.74s/it]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 500\n",
    "total_batches = (len(df) + batch_size - 1) // batch_size\n",
    "\n",
    "for i in tqdm(range(total_batches), desc=\"Processing Batches\"):\n",
    "    dfc = df[i*batch_size:(i+1)*batch_size].reset_index(drop=True)\n",
    "    dfc[\"keywords\"] = dfc[COLUMN].apply(extract_keywords, nlp=nlp)\n",
    "    dfc.keywords = dfc.keywords.apply(lambda v: [morph.parse(w)[0].normal_form for w in v])\n",
    "    dfc.keywords = dfc.keywords.apply(lambda v: \" \".join(v))\n",
    "    df_keywords = pd.concat([df_keywords, dfc]).reset_index(drop=True)\n",
    "    if i % 10 == 0:\n",
    "        df_keywords.to_parquet(\n",
    "            data_path+f\"keywords/{i}_df_keywords.parquet.gzip\", compression=\"gzip\", index=False\n",
    "        )\n",
    "df_keywords.to_parquet(\n",
    "    data_path+f\"keywords/_df_keywords.parquet.gzip\", compression=\"gzip\", index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1694dc0-2721-4dda-bce9-965b8acf656b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
