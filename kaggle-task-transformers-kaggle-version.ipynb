{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers \n!pip install datasets\n!pip install tokenizers\n!pip install transformers[torch]\n!pip install accelerate -U","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-09-30T17:25:36.491475Z","iopub.execute_input":"2023-09-30T17:25:36.491864Z","iopub.status.idle":"2023-09-30T17:26:24.124914Z","shell.execute_reply.started":"2023-09-30T17:25:36.491841Z","shell.execute_reply":"2023-09-30T17:26:24.123601Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.15)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.12.2)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.13.3)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch!=1.12.0,>=1.10 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.0.0)\nRequirement already satisfied: accelerate>=0.20.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers[torch]) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.22.0)\nCollecting accelerate\n  Downloading accelerate-0.23.0-py3-none-any.whl (258 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.1/258.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.16.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2023.9.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nInstalling collected packages: accelerate\n  Attempting uninstall: accelerate\n    Found existing installation: accelerate 0.22.0\n    Uninstalling accelerate-0.22.0:\n      Successfully uninstalled accelerate-0.22.0\nSuccessfully installed accelerate-0.23.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport string\nimport torch\nfrom sklearn.model_selection import train_test_split\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\nfrom transformers import Trainer, TrainingArguments\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:21:27.867397Z","iopub.execute_input":"2023-09-30T18:21:27.867721Z","iopub.status.idle":"2023-09-30T18:21:50.778745Z","shell.execute_reply.started":"2023-09-30T18:21:27.867694Z","shell.execute_reply":"2023-09-30T18:21:50.777881Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"fPath = \"/kaggle/input/unit-3-sentiment/\"\ndf = pd.read_csv(fPath + \"train.csv\")\n\n# drop rows with empty target\ndf = df[~df.Sentiment.isna()].reset_index(drop=True)\ndf.drop(\"Unnamed: 0\", axis=1, inplace=True)\n\nprint(df.shape)\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:27:43.767589Z","iopub.execute_input":"2023-09-30T18:27:43.767944Z","iopub.status.idle":"2023-09-30T18:27:43.923420Z","shell.execute_reply.started":"2023-09-30T18:27:43.767891Z","shell.execute_reply":"2023-09-30T18:27:43.922360Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"(41155, 2)\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                Text Sentiment\n0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   Neutral\n1  advice Talk to your neighbours family to excha...  Positive\n2  Coronavirus Australia: Woolworths to give elde...  Positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Text</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## preprocess","metadata":{}},{"cell_type":"code","source":"# encoding string labels\nno_labels = df.Sentiment.nunique()\nlabels_dict = dict(zip(df.Sentiment.unique(), range(no_labels)))\nprint(labels_dict)\ndf.Sentiment = df.Sentiment.map(labels_dict)\n\n# check the target ditribution\nax = df.groupby(\"Sentiment\").count().plot(kind=\"bar\", legend=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:27:45.414691Z","iopub.execute_input":"2023-09-30T18:27:45.415067Z","iopub.status.idle":"2023-09-30T18:27:45.664634Z","shell.execute_reply.started":"2023-09-30T18:27:45.415037Z","shell.execute_reply":"2023-09-30T18:27:45.663689Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"{'Neutral': 0, 'Positive': 1, 'Extremely Negative': 2, 'Negative': 3, 'Extremely Positive': 4}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"def remove_links(v):\n    # remove https links\n    return re.sub(r\"https\\S+\",\"\", v)\n\ndef remove_calls(v):\n    # remove @text\n    return re.sub(r\"@\\S+\",\"\", v)\n\ndef remove_punctuation(v):\n    # remove special chars\n    return re.sub(f\"[{re.escape(string.punctuation)}]\", '', v)\n\ndef remove_chars(v):\n    # remove special chars\n    chars = [\"\\n\", \"\\t\", \"\\r\", \"<br>\"]\n    for char in chars:\n        v = v.replace(char, \"\")\n    return v\n\ndef remove_digits(v):\n    # remove digits\n    return re.sub(r\"\\d\", \"\", v)\n\ndef remove_emojis(data):\n    # remove emojis\n    emoj = re.compile(\"[\"\n        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n        u\"\\U00002500-\\U00002BEF\"  # chinese char\n        u\"\\U00002702-\\U000027B0\"\n        u\"\\U000024C2-\\U0001F251\"\n        u\"\\U0001f926-\\U0001f937\"\n        u\"\\U00010000-\\U0010ffff\"\n        u\"\\u2640-\\u2642\" \n        u\"\\u2600-\\u2B55\"\n        u\"\\u200d\"\n        u\"\\u23cf\"\n        u\"\\u23e9\"\n        u\"\\u231a\"\n        u\"\\ufe0f\"  # dingbats\n        u\"\\u3030\"\n                      \"]+\", re.UNICODE)\n    return re.sub(emoj, '', data)\n\n    \ndf.Text = df.Text.apply(remove_links)\ndf.Text = df.Text.apply(remove_calls)\ndf.Text = df.Text.apply(remove_punctuation)\ndf.Text = df.Text.apply(remove_chars)\ndf.Text = df.Text.apply(remove_digits)\ndf.Text = df.Text.apply(remove_emojis)\n\n# lower the text\ndf.Text = df.Text.str.lower()\n# remove rows with the text too short\nmin_text_len = 20\ndf = df[~df.Text.str.len()<min_text_len].reset_index(drop=True)\nprint(\"preprocess completed\")","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:27:47.875584Z","iopub.execute_input":"2023-09-30T18:27:47.875941Z","iopub.status.idle":"2023-09-30T18:27:48.804483Z","shell.execute_reply.started":"2023-09-30T18:27:47.875881Z","shell.execute_reply":"2023-09-30T18:27:48.803538Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"preprocess completed\n","output_type":"stream"}]},{"cell_type":"code","source":"xtr, xvl, ytr, yvl = train_test_split(df.Text, df.Sentiment, test_size=0.2, random_state=42)\n\nxtr = xtr.reset_index(drop=True)\nxvl = xvl.reset_index(drop=True)\nytr = ytr.reset_index(drop=True)\nyvl = yvl.reset_index(drop=True)\n\nprint(xtr.shape, xvl.shape, ytr.shape, yvl.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:27:54.252158Z","iopub.execute_input":"2023-09-30T18:27:54.252786Z","iopub.status.idle":"2023-09-30T18:27:54.280773Z","shell.execute_reply.started":"2023-09-30T18:27:54.252757Z","shell.execute_reply":"2023-09-30T18:27:54.279655Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(32924,) (8231,) (32924,) (8231,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## fit the model","metadata":{}},{"cell_type":"code","source":"#@title tokenize data\n\nmodel_id = \"bert-base-uncased\"\ntokenizer = AutoTokenizer.from_pretrained(model_id)\n\nclass CustomDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {\n            'input_ids': self.encodings['input_ids'][idx],\n            'attention_mask': self.encodings['attention_mask'][idx],\n            'labels': torch.tensor(self.labels[idx])\n        }\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_tokenized = tokenizer(list(xtr), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\neval_tokenized = tokenizer(list(xvl), padding='max_length', truncation=True, max_length=128, return_tensors='pt')\n\ntrain_dataset = CustomDataset(train_tokenized, ytr)\neval_dataset = CustomDataset(test_tokenized, yvl)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:28:24.676882Z","iopub.execute_input":"2023-09-30T18:28:24.677243Z","iopub.status.idle":"2023-09-30T18:28:35.010945Z","shell.execute_reply.started":"2023-09-30T18:28:24.677216Z","shell.execute_reply":"2023-09-30T18:28:35.009685Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"\n!mkdir data\n\nOUTPUT_DIR = \"/kaggle/working/model\"\n\nmodel = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=no_labels)\ndata_collator = DataCollatorWithPadding(tokenizer)\n\ntrain_args = TrainingArguments(\n    output_dir = OUTPUT_DIR,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=train_args,\n    data_collator=data_collator,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-09-30T18:29:03.207821Z","iopub.execute_input":"2023-09-30T18:29:03.208165Z","iopub.status.idle":"2023-09-30T18:59:52.574502Z","shell.execute_reply.started":"2023-09-30T18:29:03.208139Z","shell.execute_reply":"2023-09-30T18:59:52.573502Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nmkdir: cannot create directory ‘data’: File exists\n","output_type":"stream"},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6174' max='6174' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6174/6174 30:45, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>1.146500</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.793500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.697500</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.629600</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.485300</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.438100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.416200</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.399900</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.303000</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.259200</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.252400</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.224300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=6174, training_loss=0.49564704363655804, metrics={'train_runtime': 1846.272, 'train_samples_per_second': 53.498, 'train_steps_per_second': 3.344, 'total_flos': 6497176291863552.0, 'train_loss': 0.49564704363655804, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir kaggle/working/model","metadata":{"execution":{"iopub.status.busy":"2023-09-25T15:01:10.564384Z","iopub.execute_input":"2023-09-25T15:01:10.564816Z","iopub.status.idle":"2023-09-25T15:01:11.681442Z","shell.execute_reply.started":"2023-09-25T15:01:10.564782Z","shell.execute_reply":"2023-09-25T15:01:11.679544Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nmkdir: cannot create directory ‘kaggle/working/model’: No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.save_model(OUTPUT_DIR)\nOUTPUT_DIR = OUTPUT_DIR = \"/kaggle/working/model\"\ntrainer.save_model(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR) ","metadata":{"execution":{"iopub.status.busy":"2023-09-25T15:02:06.041531Z","iopub.execute_input":"2023-09-25T15:02:06.042727Z","iopub.status.idle":"2023-09-25T15:02:06.794167Z","shell.execute_reply.started":"2023-09-25T15:02:06.042672Z","shell.execute_reply":"2023-09-25T15:02:06.792194Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"if False:\n    from IPython.display import FileLink\n    FileLink(r'file.zip')","metadata":{"execution":{"iopub.status.busy":"2023-09-25T15:07:13.277004Z","iopub.execute_input":"2023-09-25T15:07:13.277418Z","iopub.status.idle":"2023-09-25T15:07:13.292977Z","shell.execute_reply.started":"2023-09-25T15:07:13.277381Z","shell.execute_reply":"2023-09-25T15:07:13.290514Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/file.zip","text/html":"<a href='file.zip' target='_blank'>file.zip</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"## predict text","metadata":{}},{"cell_type":"code","source":"# read test\ndf_test = pd.read_csv(fPath + \"test.csv\")\n\n# preprocess test\ndf_test.Text = df_test.Text.apply(remove_links)\ndf_test.Text = df_test.Text.apply(remove_calls)\ndf_test.Text = df_test.Text.apply(remove_punctuation)\ndf_test.Text = df_test.Text.apply(remove_chars)\ndf_test.Text = df_test.Text.apply(remove_digits)\ndf_test.Text = df_test.Text.apply(remove_emojis)\ndf_test.Text = df_test.Text.str.lower()\n","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:07:52.524680Z","iopub.execute_input":"2023-09-30T19:07:52.525080Z","iopub.status.idle":"2023-09-30T19:07:52.643305Z","shell.execute_reply.started":"2023-09-30T19:07:52.525050Z","shell.execute_reply":"2023-09-30T19:07:52.642222Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"# get predictions\n\nall_labels = []\nfor i in range(len(df_test)//20+1): # due to RAM limitations\n    \n    input_text = df_test.Text.iloc[i*20:(1+i)*20].tolist()\n    input_tokenized = tokenizer(input_text, padding='max_length', truncation=True, max_length=128, return_tensors='pt').to(device)\n    with torch.no_grad():\n        output = model(**input_tokenized)\n    logits = output.logits\n    predicted_probabilities = torch.softmax(logits, dim=1)\n    predicted_labels = torch.argmax(predicted_probabilities, dim=1)\n    predicted_labels = predicted_labels.tolist()\n    all_labels.append(predicted_labels)\n    \nall_labels = [l for sl in all_labels for l in sl]","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:19:18.336862Z","iopub.execute_input":"2023-09-30T19:19:18.337228Z","iopub.status.idle":"2023-09-30T19:19:43.462118Z","shell.execute_reply.started":"2023-09-30T19:19:18.337203Z","shell.execute_reply":"2023-09-30T19:19:43.460834Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# decode labels\ndecode_labels_dict = {k:v for v,k in labels_dict.items()} \nall_labels = [decode_labels_dict[x] for x in all_labels]\n# submit\nsubmission = pd.read_csv(fPath + \"sample_submission.csv\")\nsubmission.Sentiment = all_labels\nsubmission.to_csv(\"data/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:31:53.999404Z","iopub.execute_input":"2023-09-30T19:31:53.999773Z","iopub.status.idle":"2023-09-30T19:31:54.006601Z","shell.execute_reply.started":"2023-09-30T19:31:53.999746Z","shell.execute_reply":"2023-09-30T19:31:54.005637Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# import os\n# os.environ[\"KAGGLE_USERNAME\"]=\n# os.environ[\"KAGGLE_KEY\"]=","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:41:18.424055Z","iopub.execute_input":"2023-09-30T19:41:18.424533Z","iopub.status.idle":"2023-09-30T19:41:18.435218Z","shell.execute_reply.started":"2023-09-30T19:41:18.424490Z","shell.execute_reply":"2023-09-30T19:41:18.434291Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"!kaggle competitions submit -c unit-3-nlp-txt-classification -f data/submission.csv -m \"*\"","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:41:21.337504Z","iopub.execute_input":"2023-09-30T19:41:21.337839Z","iopub.status.idle":"2023-09-30T19:41:26.171791Z","shell.execute_reply.started":"2023-09-30T19:41:21.337809Z","shell.execute_reply":"2023-09-30T19:41:26.170539Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n100%|████████████████████████████████████████| 181k/181k [00:02<00:00, 88.2kB/s]\nSuccessfully submitted to Unit 3 - Классификация текстов","output_type":"stream"}]},{"cell_type":"code","source":"!ls data","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:38:05.096701Z","iopub.execute_input":"2023-09-30T19:38:05.097122Z","iopub.status.idle":"2023-09-30T19:38:06.591288Z","shell.execute_reply.started":"2023-09-30T19:38:05.097087Z","shell.execute_reply":"2023-09-30T19:38:06.588837Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stdout","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\nsample_submission.csv  submission.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!kaggle competitions submit -c h-and-m-personalized-fashion-recommendations  -f ../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv -m \"Submission via API\"","metadata":{"execution":{"iopub.status.busy":"2023-09-30T19:33:05.138597Z","iopub.execute_input":"2023-09-30T19:33:05.138969Z","iopub.status.idle":"2023-09-30T19:33:05.145369Z","shell.execute_reply.started":"2023-09-30T19:33:05.138939Z","shell.execute_reply":"2023-09-30T19:33:05.144247Z"},"trusted":true},"execution_count":75,"outputs":[]}]}